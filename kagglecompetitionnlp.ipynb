{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# input dataset to notebook\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-26T02:49:13.359882Z","iopub.execute_input":"2022-10-26T02:49:13.361078Z","iopub.status.idle":"2022-10-26T02:49:13.379150Z","shell.execute_reply.started":"2022-10-26T02:49:13.361030Z","shell.execute_reply":"2022-10-26T02:49:13.378048Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"/kaggle/input/training/simpsons_dataset-training.tsv\n/kaggle/input/testing/simpsons_dataset-testing.tsv\n/kaggle/input/submission/simpsons_dataset-sample_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:13.381773Z","iopub.execute_input":"2022-10-26T02:49:13.382584Z","iopub.status.idle":"2022-10-26T02:49:13.395428Z","shell.execute_reply.started":"2022-10-26T02:49:13.382548Z","shell.execute_reply":"2022-10-26T02:49:13.394399Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/input/training/simpsons_dataset-training.tsv\n/kaggle/input/testing/simpsons_dataset-testing.tsv\n/kaggle/input/submission/simpsons_dataset-sample_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import BERT tokenization\n!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:13.397219Z","iopub.execute_input":"2022-10-26T02:49:13.397869Z","iopub.status.idle":"2022-10-26T02:49:14.733249Z","shell.execute_reply.started":"2022-10-26T02:49:13.397835Z","shell.execute_reply":"2022-10-26T02:49:14.731867Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# reading training ,testing,and sample_submission dataset\ntrain=pd.read_csv('/kaggle/input/training/simpsons_dataset-training.tsv',sep='\\t')\ntest=pd.read_csv('/kaggle/input/testing/simpsons_dataset-testing.tsv',sep='\\t')\nsubmission= pd.read_csv('/kaggle/input/submission/simpsons_dataset-sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:14.735827Z","iopub.execute_input":"2022-10-26T02:49:14.736495Z","iopub.status.idle":"2022-10-26T02:49:14.842476Z","shell.execute_reply.started":"2022-10-26T02:49:14.736432Z","shell.execute_reply":"2022-10-26T02:49:14.841393Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:14.844109Z","iopub.execute_input":"2022-10-26T02:49:14.844818Z","iopub.status.idle":"2022-10-26T02:49:14.862537Z","shell.execute_reply.started":"2022-10-26T02:49:14.844778Z","shell.execute_reply":"2022-10-26T02:49:14.861118Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"id          0\nclass       0\nsubclass    0\ntext        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"removing missing values","metadata":{}},{"cell_type":"code","source":"train = train.dropna().reset_index(drop=True)\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:14.863958Z","iopub.execute_input":"2022-10-26T02:49:14.865240Z","iopub.status.idle":"2022-10-26T02:49:14.893306Z","shell.execute_reply.started":"2022-10-26T02:49:14.865203Z","shell.execute_reply":"2022-10-26T02:49:14.892217Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"id          0\nclass       0\nsubclass    0\ntext        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"removing stopwords","metadata":{}},{"cell_type":"code","source":"import spacy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) \n\ndef cleaning(doc):\n    # Lemmatizes and removes stopwords\n    # doc needs to be a spacy Doc object\n    txt = [ token.lemma_ for token in doc if not token.is_stop]\n    if len(txt) > 2:\n        return ' '.join(txt)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:14.894707Z","iopub.execute_input":"2022-10-26T02:49:14.895295Z","iopub.status.idle":"2022-10-26T02:49:15.472958Z","shell.execute_reply.started":"2022-10-26T02:49:14.895259Z","shell.execute_reply":"2022-10-26T02:49:15.471857Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Remove all non-alphabetic characters","metadata":{}},{"cell_type":"code","source":"brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in train['text'])","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:15.474560Z","iopub.execute_input":"2022-10-26T02:49:15.474929Z","iopub.status.idle":"2022-10-26T02:49:15.480406Z","shell.execute_reply.started":"2022-10-26T02:49:15.474892Z","shell.execute_reply":"2022-10-26T02:49:15.479315Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from time import time\nimport re\nt = time()\ntxt = [ cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=-1)]\n\nprint('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:49:15.481973Z","iopub.execute_input":"2022-10-26T02:49:15.482709Z","iopub.status.idle":"2022-10-26T02:50:23.278022Z","shell.execute_reply.started":"2022-10-26T02:49:15.482661Z","shell.execute_reply":"2022-10-26T02:50:23.276564Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Time to clean up everything: 1.13 mins\n","output_type":"stream"}]},{"cell_type":"code","source":"#install package needed\npip install tokenization","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:50:23.293407Z","iopub.execute_input":"2022-10-26T02:50:23.294150Z","iopub.status.idle":"2022-10-26T02:50:32.767246Z","shell.execute_reply.started":"2022-10-26T02:50:23.294097Z","shell.execute_reply":"2022-10-26T02:50:32.766138Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tokenization in /opt/conda/lib/python3.7/site-packages (1.0.7)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from tokenization) (2021.11.10)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"#install package needed\npip install bert-for-tf2","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:50:32.768996Z","iopub.execute_input":"2022-10-26T02:50:32.769369Z","iopub.status.idle":"2022-10-26T02:50:47.924793Z","shell.execute_reply.started":"2022-10-26T02:50:32.769331Z","shell.execute_reply":"2022-10-26T02:50:47.923470Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Collecting bert-for-tf2\n  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m799.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py-params>=0.9.6\n  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting params-flow>=0.8.0\n  Downloading params-flow-0.8.2.tar.gz (22 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\nBuilding wheels for collected packages: bert-for-tf2, params-flow, py-params\n  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=2e98e02aa6a2a4b1e6851b7c4256ab4c75eb0dd270ead7d25c5eecd67e1d906a\n  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n  Building wheel for params-flow (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=d574ed9fd7e7f427f1810729333177316bf71121387f1b7a2488d702f6cd10ff\n  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n  Building wheel for py-params (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=84c12c934f89378267a3da5a0ab0147f43560b4da9aa0365a4a9ea89f28cea6e\n  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\nSuccessfully built bert-for-tf2 params-flow py-params\nInstalling collected packages: py-params, params-flow, bert-for-tf2\nSuccessfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from bert import bert_tokenization\nimport tokenization\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:50:47.926540Z","iopub.execute_input":"2022-10-26T02:50:47.927297Z","iopub.status.idle":"2022-10-26T02:50:49.163467Z","shell.execute_reply.started":"2022-10-26T02:50:47.927249Z","shell.execute_reply":"2022-10-26T02:50:49.162304Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#lable characters \nlabel = preprocessing.LabelEncoder()\ny = label.fit_transform(train['class'])\ny = to_categorical(y)\nprint(y[:5])","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:50:49.164765Z","iopub.execute_input":"2022-10-26T02:50:49.167001Z","iopub.status.idle":"2022-10-26T02:50:49.197823Z","shell.execute_reply.started":"2022-10-26T02:50:49.166970Z","shell.execute_reply":"2022-10-26T02:50:49.195898Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"[[1. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]]\n","output_type":"stream"}]},{"cell_type":"code","source":"#creating a bert embedding layer by importing the BERT model from hub.KerasLayer\nm_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\nbert_layer = hub.KerasLayer(m_url, trainable=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:50:49.199392Z","iopub.execute_input":"2022-10-26T02:50:49.199840Z","iopub.status.idle":"2022-10-26T02:51:07.198167Z","shell.execute_reply.started":"2022-10-26T02:50:49.199796Z","shell.execute_reply":"2022-10-26T02:51:07.197202Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"2022-10-26 02:50:53.864532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:50:53.865765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:50:53.866475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:50:53.867265: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-10-26 02:50:53.867554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:50:53.868227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:50:53.868848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:51:02.267854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:51:02.268648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:51:02.269269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 02:51:02.269827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14651 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ntrain['Category'] = encoder.fit_transform(train['class'])","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:07.199471Z","iopub.execute_input":"2022-10-26T02:51:07.199829Z","iopub.status.idle":"2022-10-26T02:51:07.216691Z","shell.execute_reply.started":"2022-10-26T02:51:07.199793Z","shell.execute_reply":"2022-10-26T02:51:07.215717Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"encoding text","metadata":{}},{"cell_type":"code","source":"# build a vocab_file in the form of numpy array\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n# convert all leters to lowercase\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n#pass the previous two items to the Tokenizer object\ntokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n\ndef bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    for text in texts:\n        text = tokenizer.tokenize(text)\n        \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len-len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n        \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:07.219342Z","iopub.execute_input":"2022-10-26T02:51:07.220055Z","iopub.status.idle":"2022-10-26T02:51:07.324986Z","shell.execute_reply.started":"2022-10-26T02:51:07.220019Z","shell.execute_reply":"2022-10-26T02:51:07.324008Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Building a model\nFunction we will be using:\nRelu\nSofatmax\nCross-entropy:compute cross-entropy loss between real label and predicted label","metadata":{}},{"cell_type":"code","source":"\ndef build_model(bert_layer, max_len=512):\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    \n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    clf_output = sequence_output[:, 0, :]\n    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n    lay = tf.keras.layers.Dropout(0.2)(lay)\n    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n    lay = tf.keras.layers.Dropout(0.2)(lay)\n    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:07.326297Z","iopub.execute_input":"2022-10-26T02:51:07.327009Z","iopub.status.idle":"2022-10-26T02:51:07.336756Z","shell.execute_reply.started":"2022-10-26T02:51:07.326962Z","shell.execute_reply":"2022-10-26T02:51:07.335816Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#check each text, we set the length of text as 250 characters\nmax_len = 250\ntrain_input = bert_encode(train.text.values, tokenizer, max_len=max_len)\ntest_input = bert_encode(test.text.values, tokenizer, max_len=max_len)\ntrain_labels = y","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:07.338510Z","iopub.execute_input":"2022-10-26T02:51:07.338944Z","iopub.status.idle":"2022-10-26T02:51:25.847530Z","shell.execute_reply.started":"2022-10-26T02:51:07.338907Z","shell.execute_reply":"2022-10-26T02:51:25.846516Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#define and print labels ,these are character categories s for our submission\nlabels = label.classes_\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:25.849107Z","iopub.execute_input":"2022-10-26T02:51:25.849497Z","iopub.status.idle":"2022-10-26T02:51:25.855087Z","shell.execute_reply.started":"2022-10-26T02:51:25.849459Z","shell.execute_reply":"2022-10-26T02:51:25.854016Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"['Bart Simpson' 'Homer Simpson' 'Lisa Simpson' 'Marge Simpson' 'Other']\n","output_type":"stream"}]},{"cell_type":"code","source":"#preveiew model\nmodel = build_model(bert_layer, max_len=max_len)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:25.856541Z","iopub.execute_input":"2022-10-26T02:51:25.857210Z","iopub.status.idle":"2022-10-26T02:51:26.772754Z","shell.execute_reply.started":"2022-10-26T02:51:25.857140Z","shell.execute_reply":"2022-10-26T02:51:26.771724Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_word_ids (InputLayer)     [(None, 250)]        0                                            \n__________________________________________________________________________________________________\ninput_mask (InputLayer)         [(None, 250)]        0                                            \n__________________________________________________________________________________________________\nsegment_ids (InputLayer)        [(None, 250)]        0                                            \n__________________________________________________________________________________________________\nkeras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n                                                                 input_mask[0][0]                 \n                                                                 segment_ids[0][0]                \n__________________________________________________________________________________________________\ntf.__operators__.getitem (Slici (None, 768)          0           keras_layer[0][1]                \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           49216       tf.__operators__.getitem[0][0]   \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 64)           0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 32)           2080        dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 5)            165         dropout_1[0][0]                  \n==================================================================================================\nTotal params: 109,533,702\nTrainable params: 109,533,701\nNon-trainable params: 1\n__________________________________________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#set parameters and run the model, 10 epochs to increase the accuracy as high as possible \ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\ntrain_sh = model.fit(\n    train_input, train_labels,\n    validation_split=0.2,\n    epochs=10,\n    callbacks=[checkpoint, earlystopping],\n    batch_size=24,\n    verbose=1\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-26T02:51:26.774435Z","iopub.execute_input":"2022-10-26T02:51:26.775048Z","iopub.status.idle":"2022-10-26T06:04:18.537826Z","shell.execute_reply.started":"2022-10-26T02:51:26.775010Z","shell.execute_reply":"2022-10-26T06:04:18.535823Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"2022-10-26 02:51:27.272892: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n1622/1622 [==============================] - 1298s 792ms/step - loss: 1.4094 - accuracy: 0.4071 - val_loss: 1.2811 - val_accuracy: 0.4651\n\nEpoch 00001: val_accuracy improved from -inf to 0.46510, saving model to model.h5\nEpoch 2/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 1.2646 - accuracy: 0.4819 - val_loss: 1.2489 - val_accuracy: 0.4898\n\nEpoch 00002: val_accuracy improved from 0.46510 to 0.48977, saving model to model.h5\nEpoch 3/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 1.1121 - accuracy: 0.5599 - val_loss: 1.3218 - val_accuracy: 0.4836\n\nEpoch 00003: val_accuracy did not improve from 0.48977\nEpoch 4/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 0.9203 - accuracy: 0.6500 - val_loss: 1.3200 - val_accuracy: 0.4920\n\nEpoch 00004: val_accuracy improved from 0.48977 to 0.49203, saving model to model.h5\nEpoch 5/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 0.7178 - accuracy: 0.7414 - val_loss: 1.5189 - val_accuracy: 0.4868\n\nEpoch 00005: val_accuracy did not improve from 0.49203\nEpoch 6/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 0.5435 - accuracy: 0.8116 - val_loss: 1.7421 - val_accuracy: 0.4857\n\nEpoch 00006: val_accuracy did not improve from 0.49203\nEpoch 7/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 0.4275 - accuracy: 0.8551 - val_loss: 2.1861 - val_accuracy: 0.4837\n\nEpoch 00007: val_accuracy did not improve from 0.49203\nEpoch 8/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 0.3309 - accuracy: 0.8907 - val_loss: 2.2817 - val_accuracy: 0.4811\n\nEpoch 00008: val_accuracy did not improve from 0.49203\nEpoch 9/10\n1622/1622 [==============================] - 1283s 791ms/step - loss: 0.2649 - accuracy: 0.9147 - val_loss: 2.3115 - val_accuracy: 0.4620\n\nEpoch 00009: val_accuracy did not improve from 0.49203\nEpoch 00009: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"#export prediction as submission.csv\nmodel.load_weights('model.h5')\npreds = model.predict(test_input,verbose = 1)\npred_classes = np.argmax(preds, axis = 1)\n\n#mapping the encoded output to actual categories\npredicted_category = [labels[x] for x in pred_classes]\n\nsubmission['Category'] = predicted_category\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-10-26T06:04:18.539363Z","iopub.execute_input":"2022-10-26T06:04:18.542075Z","iopub.status.idle":"2022-10-26T06:06:46.768872Z","shell.execute_reply.started":"2022-10-26T06:04:18.542037Z","shell.execute_reply":"2022-10-26T06:06:46.767981Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"329/329 [==============================] - 105s 318ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Id       Category\n0   1   Bart Simpson\n1   2   Lisa Simpson\n2   3  Homer Simpson\n3   4   Bart Simpson\n4   5  Marge Simpson\n5   6  Homer Simpson\n6   7  Homer Simpson\n7   8  Marge Simpson\n8   9  Homer Simpson\n9  10  Marge Simpson","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Bart Simpson</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Lisa Simpson</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Homer Simpson</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Bart Simpson</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Marge Simpson</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Homer Simpson</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Homer Simpson</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Marge Simpson</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Homer Simpson</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Marge Simpson</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-26T06:06:46.770136Z","iopub.execute_input":"2022-10-26T06:06:46.770513Z","iopub.status.idle":"2022-10-26T06:06:46.778741Z","shell.execute_reply.started":"2022-10-26T06:06:46.770476Z","shell.execute_reply":"2022-10-26T06:06:46.777691Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(10499, 2)"},"metadata":{}}]}]}